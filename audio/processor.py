import vosk
import json
import numpy as np
from audio.recorder import Recorder

class SpeechProcessor:
    def __init__(self, model_path="models/vosk_model"):
        """åˆå§‹åŒ–èªéŸ³è¾¨è­˜æ¨¡çµ„"""
        self.model = vosk.Model(model_path)
        self.recognizer = vosk.KaldiRecognizer(self.model, 16000)  # å–æ¨£ç‡ 16kHz
        self.recorder = Recorder()  # å»ºç«‹éŒ„éŸ³å™¨

    def start_recording(self):
        """å•Ÿå‹•éŒ„éŸ³"""
        self.recorder.start()

    def stop_recording(self):
        """åœæ­¢éŒ„éŸ³"""
        self.recorder.stop()

    def get_command(self):
        """å¾éŒ„éŸ³ buffer å–å¾—èªéŸ³æŒ‡ä»¤"""
        audio_data = self.recorder.get_audio_buffer()  # å–å¾—éŒ„éŸ³ buffer
        if len(audio_data) == 0:
            return None  # æ²’æœ‰éŸ³è¨Šå¯è¾¨è­˜
        # è½‰æ›éŸ³è¨Šç‚º bytes æ ¼å¼ï¼ˆç¬¦åˆ Vosk éœ€æ±‚ï¼‰
        audio_bytes = np.array(audio_data, dtype=np.int16).tobytes()

        # é€²è¡ŒèªéŸ³è¾¨è­˜
        if self.recognizer.AcceptWaveform(audio_bytes):
            result = json.loads(self.recognizer.Result())
            text = result["text"]  # å–å¾—è¾¨è­˜æ–‡å­—ï¼ˆä¿æŒåŸæ¨£ï¼‰

            # å®šç¾©é—œéµè©
            commands = {"å‰": "forward", "å·¦": "left", "å³": "right"}

            # **æª¢æŸ¥ text ä¸­æ˜¯å¦åŒ…å«ä»»ä½•é—œéµè©**
            for word in commands:
                if word in text:  # å¦‚æœé—œéµè©å‡ºç¾åœ¨ `text` è£¡
                    return commands[word]  # å›å‚³å°æ‡‰çš„æŒ‡ä»¤
            else:
                print(f"ğŸ” ç„¡æ³•è¾¨è­˜æŒ‡ä»¤ï¼š{text}")
        return None  # æ²’æœ‰åµæ¸¬åˆ°æœ‰æ•ˆæŒ‡ä»¤

